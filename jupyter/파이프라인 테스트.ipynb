{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d434d34-51a0-4bd0-b6b1-ef4236b52988",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['../test_data/html\\\\https%3A%2F%2Fpython.langchain.com%2Fapi_reference%2F_f36a1545.html', '../test_data/html\\\\https%3A%2F%2Fpython.langchain.com%2Fdocs%2Fcontributing%2F_7821225b.html', '../test_data/html\\\\https%3A%2F%2Fpython.langchain.com%2Fdocs%2Fhow_to%2Fadd_scores_retriever%2F_675ddc58.html', '../test_data/html\\\\https%3A%2F%2Fpython.langchain.com%2Fdocs%2Fhow_to%2Fagent_executor%2F_6b55a70d.html', '../test_data/html\\\\https%3A%2F%2Fpython.langchain.com%2Fdocs%2Fhow_to%2Fassign%2F_b35f6acf.html']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import glob\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "path_dir_test_html = \"../test_data/html\"\n",
    "list_fpath_test_html = glob.glob(path_dir_test_html + \"/*.html\")[:5]\n",
    "\n",
    "print(list_fpath_test_html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8a1fe6c-55cc-46ca-a1a7-c3f2949ba737",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n"
     ]
    }
   ],
   "source": [
    "from docmesh.extractor.HTMLFileInspector import HTMLFileInspector\n",
    "from docmesh.text_split import HTMLContentLoader\n",
    "\n",
    "html_file_loader = HTMLFileInspector()\n",
    "html_content_loader = HTMLContentLoader()\n",
    "\n",
    "url, html = html_file_loader.read_html(list_fpath_test_html[2])\n",
    "docs_langchain = html_content_loader.load(url, html)\n",
    "\n",
    "print(len(docs_langchain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7db44abd-e8c1-4d8a-ada4-6c04df3799d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "from docmesh.text_split.DocumentMerger import DocumentMerger\n",
    "\n",
    "# ÏµúÏÜå ÌÜ†ÌÅ∞ Í∏∞Ï§ÄÏúºÎ°ú chunk Î≥ëÌï©\n",
    "doc_merger = DocumentMerger(min_tokens=500)\n",
    "docs_merged = doc_merger.merge_documents(docs_langchain)\n",
    "\n",
    "print(len(docs_merged))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "487a61a0-db8b-488b-956b-5f3f3075554a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": [
    "from docmesh.text_split.DocumentChunkSplitter import DocumentChunkSplitter\n",
    "\n",
    "doc_splitter = DocumentChunkSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "docs_splitted = doc_splitter.chunkify(docs_merged)\n",
    "\n",
    "print(len(docs_splitted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f5c9bc89-9560-4249-8a5d-e23df6a7fd99",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`embedding_function` is expected to be an Embeddings object, support for passing in a function will soon be removed.\n"
     ]
    }
   ],
   "source": [
    "from docmesh.embedding import EmbeddingModelFactory\n",
    "from docmesh.vector_store import VectorStoreFactory\n",
    "\n",
    "# EmbeddingModelFactoryÎ•º ÌÜµÌï¥ ÏûÑÎ≤†Îî© Î™®Îç∏ ÏÉùÏÑ±\n",
    "embedding_model = EmbeddingModelFactory.create_embedding_model(\n",
    "    provider=\"openai\", model_name=\"text-embedding-ada-002\"\n",
    ")\n",
    "# VectorStoreFactoryÎ•º ÌÜµÌï¥ Î≤°ÌÑ∞ Ïä§ÌÜ†Ïñ¥ ÏÉùÏÑ±\n",
    "vector_store = VectorStoreFactory.create_vector_store(\n",
    "    provider=\"faiss\", embedding_model=embedding_model, path=\"langchain_doc.faiss\", \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "253ee523-35dd-495f-bc76-624a9fd66989",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store.add_documents(docs_splitted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d324298e-ee55-4f4a-a972-dc888e8300b7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(id='3caac93b-2684-4056-9c1d-81ac350dae69', metadata={'source': 'https://python.langchain.com/docs/how_to/add_scores_retriever/', 'split_index': 0}, page_content='!function(){function t(t){document.documentElement.setAttribute(\"data-theme\",t)}var e=function(){try{return new URLSearchParams(window.location.search).get(\"docusaurus-theme\")}catch(t){}}()||function(){try{return window.localStorage.getItem(\"theme\")}catch(t){}}();null!==e?t(e):window.matchMedia(\"(prefers-color-scheme: dark)\").matches?t(\"dark\"):(window.matchMedia(\"(prefers-color-scheme: light)\").matches,t(\"light\"))}(),function(){try{const n=new URLSearchParams(window.location.search).entries();for(var[t,e]of n)if(t.startsWith(\"docusaurus-data-\")){var a=t.replace(\"docusaurus-data-\",\"data-\");document.documentElement.setAttribute(a,e)}}catch(t){}}(),document.documentElement.setAttribute(\"data-announcement-bar-initially-dismissed\",function(){try{return\"true\"===localStorage.getItem(\"docusaurus.announcement.dismiss\")}catch(t){}return!1}())  \\nSkip to main content  \\nJoin us at   on May 13 & 14 in San Francisco!  \\nInterrupt: The Agent AI Conference by LangChain  \\nIntegrations  \\nAPI Reference  \\nMore  \\nContributing  \\nPeople  \\nError reference  \\nLangSmith  \\nLangGraph  \\nLangChain Hub  \\nLangChain JS/TS  \\nv0.3  \\nv0.3  \\nv0.2  \\nv0.1  \\nüí¨  \\nSearch  \\nIntroduction  \\nTutorials  \\nBuild a Question Answering application over a Graph Database  \\nTutorials  \\nBuild a simple LLM application with chat models and prompt templates  \\nBuild a Chatbot  \\nBuild a Retrieval Augmented Generation (RAG) App: Part 2  \\nBuild an Extraction Chain  \\nBuild an Agent  \\nTagging  \\nBuild a Retrieval Augmented Generation (RAG) App: Part 1  \\nBuild a semantic search engine  \\nBuild a Question/Answering system over SQL data  \\nSummarize Text  \\nHow-to guides  \\nHow-to guides  \\nHow to use tools in a chain  \\nHow to use a vectorstore as a retriever  \\nHow to add memory to chatbots  \\nHow to use example selectors  \\nHow to add a semantic layer over graph database  \\nHow to invoke runnables in parallel  \\nHow to stream chat model responses  \\nHow to add default invocation args to a Runnable  \\nHow to add retrieval to chatbots  \\nHow to use few shot examples in chat models  \\nHow to do tool/function calling  \\nHow to install LangChain packages  \\nHow to add examples to the prompt for query analysis  \\nHow to use few shot examples  \\nHow to run custom functions  \\nHow to use output parsers to parse an LLM response into structured format  \\nHow to handle cases where no queries are generated  \\nHow to route between sub-chains  \\nHow to return structured data from a model  \\nHow to summarize text through parallelization  \\nHow to summarize text through iterative refinement  \\nHow to summarize text in a single LLM call  \\nHow to use toolkits  \\nHow to add ad-hoc tool calling capability to LLMs and Chat Models  \\nBuild an Agent with AgentExecutor (Legacy)  \\nHow to construct knowledge graphs  \\nHow to partially format prompt templates  \\nHow to handle multiple queries when doing query analysis  \\nHow to use built-in tools and toolkits  \\nHow to pass through arguments from one step to the next  \\nHow to compose prompts together  \\nHow to handle multiple retrievers when doing query analysis  \\nHow to add values to a chain\\'s state  \\nHow to construct filters for query analysis  \\nHow to configure runtime chain internals  \\nHow deal with high cardinality categoricals when doing query analysis  \\nCustom Document Loader')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = vector_store.search(\"what is rag?\")\n",
    "query[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d2c99e5-ec82-4b3e-ab8a-dca6fb1fb94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from docmesh.llm import LLMFactory\n",
    "from docmesh.config import Config\n",
    "from docmesh.qa_bot import QAService"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fe2f5453-918e-494f-b852-f21979be6011",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. LLM ÏÑúÎπÑÏä§ ÏÉùÏÑ± (Ìå©ÌÜ†Î¶¨ ÏÇ¨Ïö©)\n",
    "llm = LLMFactory.create_llm_service(\n",
    "    provider=Config.LLM_PROVIDER,\n",
    "    model=Config.LLM_MODEL,\n",
    "    temperature=Config.LLM_TEMPERATURE,\n",
    ")\n",
    "\n",
    "retriever = vector_store.vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b175a88c-1061-469e-9eed-e99e406ee4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "bot = QAService(llm, retriever)\n",
    "bot.answer_question(\"langchainÏù¥ÎûÄ Î¨¥ÏóáÏûÖÎãàÍπå\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c30d6036-92fa-4b1a-9bc7-4db3ae64c734",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I do not know.\\n\\nSources: N/A'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bot.answer_question(\"ÏïÑÏù∏ÏäàÌÉÄÏù∏Ïùò ÏÉùÏùºÏùÑ ÏïåÎ†§Ï£ºÏÑ∏Ïöî\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b4af32-f5f9-4e02-ace3-41fef62ea28d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
